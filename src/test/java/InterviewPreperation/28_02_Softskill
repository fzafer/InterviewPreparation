* SDLC (Software Development Life Cycle)
    Software Development Life Cycle. is a process used by the software industry to design,
    develop and test a software with the high quality (customer needs), lowest cost and in the shortest time.

    1-Requirement Gathering ->Business Team -> SRS document(Software Requirement Specification)
    2-Designing ->Designers -> SDS Document
    3-Developing -> Developers -> Initial version of the project
    4-Testing -> Testers -> Bug free project/software
    5-Production -> Client,End Users -> End user uses the product
    6-Maintenance -> Developers -> Provide support

* Unit Testing/White Box Testing
    Unit Testing -> by Developers
                    Smallest part of Codes
                    White Box Testing -> code knowledge is necessary

* Black Box Testing (Behavioral Testing)
    No necessary code knowledge
    It is a part of functional testing
    by Manuel Testers
    Automation Testers(Gray Box Testing - with partial knowledge)

* Acceptance Criteria
    -Acceptance criteria refer to a set of predefined requirements
    -that must be met to mark a user story complete
    written by PO or BA

* Requirements
    Expected functionalities/specifications about software

* Testing levels (UAT testing) Unit, component testing, integration testing.

    Testing levels?
    1.    Software Testing:
            a.    Static testing (Verification process)
                i.    Req gathering
                ii.    Designing
            b.    Dynamic testing (validation process)
                i.    Testing Levels
                1.    Unit testing:
                     a.    First level of testing.
                     b.    Test the software’s individual unit or module from the developer’s code perspective.
                     c.    Also called module or component testing
                     d.    Developers write their unit tests for their code making sure that the code works correctly.
                     e.    Performed by developers
                     f.    In dev env
                     g.    Part of White box testing (devs know the internal code)

                2.    Integration testing
                     a.    Second level of testing
                     b.    Test a group of related modules to check data transfer and connectivity between units/modules
                     c.    Perf by developers (or senior testers or Q/As in some companies)
                     d.    in dev env
                     e.    part of white box testing

                3.    System testing
                     a.    3rd level
                     b.    Software or system is tested as a whole from the app perspective
                     c.    Testers compare the actual software/result with the client’s expected requirement
                     d.    Perf by QA testers, performance testers
                     e.    in QA or Test env
                     f.    Black (manual testers) or Gray box (Automation testers) testing
                     g.    Divides into two

                         i.    Functional testing
                            1.    by SDETs, test every functions as per the func reqs
                            2.    Front/end IU test
                            3.    Database
                            4.    API test
                            5.    Smoke:
                                a.    used for sw is stable or not, daily, 10-15 tests a day
                                b.    by jenkins, automaticly
                            6.    Regression: >20 tests a day
                            7.    Parallel
                            8.    Cross-browser test

                         ii.    Non functional testing
                            a.    Performance testers,
                                1.    stress,
                                2.    volume,
                                3.    capacity
                                4.    security
                                5.    installation
                                6.    speed

                4.    User Acceptance Testing
                    i.      4th level
                    ii.     evaluates whether the sw is acceptable to be released.
                    iii.    PO provides spec reqs based on real world scenarios
                    iv.     Perform by client, end users
                    v.      in staging or pre production env
                    vi.     Black (client, end user) or gray (automation testers) box testing
                           a.    alpha testing
                              -    perf by organization testers
                           b.    beta testing
                              -    perf by the client or end use


* What is STLC?

    Systematic and well-defined steps performed during the testing of SW App

    Requirement Analysis -> QA team try to understand documents created by Business Team
    Test Planing
    Test Case Development/Creation
    Test Environment Setup
    Test Execution
    Test Cycle closure

    1.    Req. analysis:
    High level rqs for per release is delivered and explained by the business team – PM PO BA (business analyst)

    2.    Test Planning
    in Agile, test planning is handled with or without a test plan doc
    Test plan doc is prepared by QA lead or senior QA
    Testers determine:
        Who are testers
        What is role & resp of each tester
        What is test strategy
            Which features will be tested
            Which testing types will be performed
            In which env testing will be performed
            Which testing tools will be used
    Due date / schedule
    What are resources of SW HW – jira AWS VM
    Input – output – entry – exit criteria

    3.    Test Case Creation
    is a doc
    QA creates test case doc per req / user story
    Test case doc used for manual / automation testing
    TC doc has: ID, description, summary, data, env, steps, actual – expected results, pass fail result

    4.    Test Env setup:
    Testers should make sure all the new codes are deployed from the dev env to the QA / Test env
    Testers manually and automatically perform testing in test-QA env

    Dev env: Unit & integration testing
    QA env: Func & non-funct  for the QA and performance testers
    Staging env UAT  the client, UAT team
    Production env End users

    5.    Test Execution
    Once the user story clear, TC are written, test data and envs are ready, testers start testing (man auto) following TC
    Expected result vs. actual result
    Not match  testers follow the bug life cycle
    •    Testers write bug reports
    •    Bugs should be fixed by devs
    •    Testers track the bugs, once fixed, testers retest to confirm bug is removed
    Update the case status pass/fail results

    6.    Test Closure
    If successfull
    Reports are auto generated
    Requirement Traceability Matrix doc prepared
    
    MANUAL TESTING
*How do we execute manual testing in our work environment? on Jira by creating test cases and test executions.
* Where do we store our test cases? in jira
* Where do we write our Manuel test cases in our work environment? in Jira,QA environment.
* Who decides priority? development team and business team together

* How and who decides severity? tester define based on impact of defect on app. eg:if it is critical than it is imp.
* What is scenario? What is test cases?
 test case is a document to show how to test.
scenario is one sentence explaning what to test clearly.
* **
 AGILE 
* What is the difference between Agile and Waterfall?
Waterfall: 1. take the SDLC step by step 
                2. there is no going back to the previous step 

 Agile
               0. welcome changes : as long as the client wants to update the req, it's gonna be updated 
               1. communication 
               2. involve the client during the SDLC 
               3. put the project on the market faster 

* Advantages and Disadvantages of Agile and Waterfall?
Advantages:
  - waterfall : suitable for clear req. , small project, for government- security projects

   - Agile: can handle even the complicated projects
               frequently releasing the app
               invite the client to get feedback in a short time


* What kind of agile ceremonies we are following in our work environment?

 Scrum meeting:
                          1. Grooming: 
                           1. The PO explains the US & AC to the dev team 
                          2. The dev team assign points to the US based on the Fibonacci 
                          1,2,3,5,8,13,21 

   
   2. Sprint planning: 
      1. SM creates a sprint backlog (on Jira app, just click a button to do so)
      2. SM & the dev team calculated the team capacity 
      3. PO take/pull US from the PB to the SB based on the DOR list (definition of readiness)
      4. SM starts the sprint & write our Sprint goal(on Jira app, just click a button to do so)

  3.Daily stand up: the SM & the dev team , 15m, in the morning at (9/10am)
                   the dev team update task status by answering 3 questions 
                               1. What did you yesterday/last business day? 
                               2. What you are doing today? 
                               3. Do you have any problem? blocker? impediment? 

                   [burn - down chart -> report, to learn remained USs]

  4.Demo: Scrum team(3 amigos,SM,PO,Dev team) + the client, PM joins 
         the dev team demo the completed US 
         PO accepts/ rejects US based on the DOD criteria/list
         any completed US are known as product increment/ potential releasable tasks
         any incomplete US/tasks will back to the PB 
         [SM -> ends/completed the SB]


 5.Retro: for the dev team to revisit the sprint & find out anything is working well? or not working well, any good ideas to make improvement 

          SM host the meeting & the dev team answer 3 questions: 
            what went wrong? 
            what went well?
            what can be done differently? new idea?  



* What is our team structure? Scrum team (product owner,development team,scrum master)

* How do we calculate team capacity? And what is our velocity ?
there is 10 working days and so 8 days left.
we need to multiply our days with workers availability. 

* How do we give points for user story? based on fibonacchi.
112358,according to t-sirt size( S,M,L )or pocker.

* What is our sprint cycle?  2 weeks generally.

* What is our release cycle? for every sprint.It depends.
release cycle:is process of developing,testing and 

* Who creates sprint backlog? SM.

* Who prioritizes user stories for sprint backlog?  PO.

* Retro meetings

+STLC

QA:Who prepares QA env?
QA1: Can BRD(business requirement document) be changed later?
QA2:Can we think initial version of product as like in qa env?

Acceptance Criteria - check list for the User Story , written PO, BA
user stories: client's requirement
